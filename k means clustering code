import pandas as pd
​
# Load the dataset
data = pd.read_csv('Mall_Customers.csv')
​
# Display the first few rows
print(data.head())
​
   CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)
0           1    Male   19                  15                      39
1           2    Male   21                  15                      81
2           3  Female   20                  16                       6
3           4  Female   23                  16                      77
4           5  Female   31                  17                      40
# Basic information about the dataset
print(data.info())
​
# Summary statistics
print(data.describe())
​
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 200 entries, 0 to 199
Data columns (total 5 columns):
 #   Column                  Non-Null Count  Dtype 
---  ------                  --------------  ----- 
 0   CustomerID              200 non-null    int64 
 1   Genre                   200 non-null    object
 2   Age                     200 non-null    int64 
 3   Annual Income (k$)      200 non-null    int64 
 4   Spending Score (1-100)  200 non-null    int64 
dtypes: int64(4), object(1)
memory usage: 7.9+ KB
None
       CustomerID         Age  Annual Income (k$)  Spending Score (1-100)
count  200.000000  200.000000          200.000000              200.000000
mean   100.500000   38.850000           60.560000               50.200000
std     57.879185   13.969007           26.264721               25.823522
min      1.000000   18.000000           15.000000                1.000000
25%     50.750000   28.750000           41.500000               34.750000
50%    100.500000   36.000000           61.500000               50.000000
75%    150.250000   49.000000           78.000000               73.000000
max    200.000000   70.000000          137.000000               99.000000
# Checking for missing values
print(data.isnull().sum())
​
# Select relevant features (e.g., Annual Income and Spending Score)
features = data[['Annual Income (k$)', 'Spending Score (1-100)']]
​
# Normalize the data
from sklearn.preprocessing import StandardScaler
​
scaler = StandardScaler()
normalized_data = scaler.fit_transform(features)
​
CustomerID                0
Genre                     0
Age                       0
Annual Income (k$)        0
Spending Score (1-100)    0
dtype: int64
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
​
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(normalized_data)
    wcss.append(kmeans.inertia_)
​
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()
​# Fit K-Means with the optimal number of clusters (let's assume it's 5 from the elbow plot)
kmeans = KMeans(n_clusters=5, random_state=42)
clusters = kmeans.fit_predict(normalized_data)

# Add cluster labels to the original data
data['Cluster'] = clusters

# Visualize the clusters
plt.scatter(normalized_data[:, 0], normalized_data[:, 1], c=clusters, cmap='viridis')
plt.title('Customer Segments')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.show()

# Display the mean values of each cluster for each feature
cluster_centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=['Annual Income (k$)', 'Spending Score (1-100)'])
cluster_centers['Cluster'] = range(5)
print(cluster_centers)

# Analyze the number of customers in each cluster
print(data['Cluster'].value_counts())

Annual Income (k$)  Spending Score (1-100)  Cluster
0           55.296296               49.518519        0
1           86.538462               82.128205        1
2           25.727273               79.363636        2
3           88.200000               17.114286        3
4           26.304348               20.913043        4
Cluster
0    81
1    39
3    35
4    23
2    22
Name: count, dtype: int64
​
